打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 1.0584, train acc 0.6545, test acc 0.8491, time 31.7 sec, tolerance 10, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.8076, train acc 0.7453, test acc 0.8780, time 30.9 sec, tolerance 10, learning rate 0.0190
打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 1.0246, train acc 0.6668, test acc 0.8492, time 31.8 sec, tolerance 10, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.8215, train acc 0.7471, test acc 0.8688, time 31.0 sec, tolerance 10, learning rate 0.0190
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 3, loss 0.7452, train acc 0.7659, test acc 0.8828, time 30.9 sec, tolerance 10, learning rate 0.0280
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.6785, train acc 0.7876, test acc 0.9134, time 30.9 sec, tolerance 10, learning rate 0.0370
epoch 5, loss 0.6703, train acc 0.7875, test acc 0.9002, time 30.9 sec, tolerance  9, learning rate 0.0460
epoch 6, loss 0.6678, train acc 0.7918, test acc 0.9091, time 30.8 sec, tolerance  8, learning rate 0.0550
epoch 7, loss 0.6216, train acc 0.8071, test acc 0.9126, time 30.9 sec, tolerance  7, learning rate 0.0640
epoch 8, loss 0.5793, train acc 0.8194, test acc 0.9098, time 30.9 sec, tolerance  6, learning rate 0.0730
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 9, loss 0.6374, train acc 0.7912, test acc 0.9175, time 30.9 sec, tolerance 10, learning rate 0.0820
epoch 10, loss 0.5641, train acc 0.8185, test acc 0.9036, time 30.9 sec, tolerance  9, learning rate 0.0910
the best accuarcy is:  0.9175
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.5522, train acc 0.8231, test acc 0.9340, time 31.1 sec, tolerance 10, learning rate 0.0200
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.4579, train acc 0.8547, test acc 0.9423, time 31.0 sec, tolerance 10, learning rate 0.0200
epoch 3, loss 0.4868, train acc 0.8412, test acc 0.9378, time 30.9 sec, tolerance  9, learning rate 0.0199
epoch 4, loss 0.5165, train acc 0.8311, test acc 0.9404, time 30.8 sec, tolerance  8, learning rate 0.0198
epoch 5, loss 0.5486, train acc 0.8220, test acc 0.9403, time 30.9 sec, tolerance  7, learning rate 0.0197
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.4521, train acc 0.8527, test acc 0.9432, time 30.9 sec, tolerance 10, learning rate 0.0195
epoch 7, loss 0.4851, train acc 0.8396, test acc 0.9425, time 30.8 sec, tolerance  9, learning rate 0.0193
epoch 8, loss 0.5107, train acc 0.8358, test acc 0.9397, time 30.9 sec, tolerance  8, learning rate 0.0190
epoch 9, loss 0.4830, train acc 0.8418, test acc 0.9397, time 30.8 sec, tolerance  7, learning rate 0.0188
epoch 10, loss 0.4633, train acc 0.8527, test acc 0.9333, time 30.8 sec, tolerance  6, learning rate 0.0184
epoch 11, loss 0.4958, train acc 0.8327, test acc 0.9432, time 30.9 sec, tolerance  5, learning rate 0.0181
epoch 12, loss 0.4551, train acc 0.8460, test acc 0.9430, time 31.0 sec, tolerance  4, learning rate 0.0177
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 13, loss 0.4294, train acc 0.8608, test acc 0.9467, time 31.0 sec, tolerance 10, learning rate 0.0173
epoch 14, loss 0.4550, train acc 0.8520, test acc 0.9414, time 30.9 sec, tolerance  9, learning rate 0.0168
epoch 15, loss 0.4334, train acc 0.8563, test acc 0.9465, time 30.9 sec, tolerance  8, learning rate 0.0164
epoch 16, loss 0.4444, train acc 0.8557, test acc 0.9411, time 30.9 sec, tolerance  7, learning rate 0.0159
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 17, loss 0.4509, train acc 0.8527, test acc 0.9491, time 31.0 sec, tolerance 10, learning rate 0.0154
epoch 18, loss 0.4272, train acc 0.8599, test acc 0.9386, time 30.8 sec, tolerance  9, learning rate 0.0148
epoch 19, loss 0.4363, train acc 0.8539, test acc 0.9385, time 30.9 sec, tolerance  8, learning rate 0.0143
epoch 20, loss 0.4126, train acc 0.8629, test acc 0.9483, time 30.9 sec, tolerance  7, learning rate 0.0137
epoch 21, loss 0.4387, train acc 0.8529, test acc 0.9441, time 30.8 sec, tolerance  6, learning rate 0.0131
epoch 22, loss 0.4647, train acc 0.8469, test acc 0.9451, time 30.8 sec, tolerance  5, learning rate 0.0125
epoch 23, loss 0.4538, train acc 0.8502, test acc 0.9490, time 30.8 sec, tolerance  4, learning rate 0.0119
epoch 24, loss 0.3866, train acc 0.8769, test acc 0.9449, time 30.8 sec, tolerance  3, learning rate 0.0113
epoch 25, loss 0.4361, train acc 0.8578, test acc 0.9468, time 30.8 sec, tolerance  2, learning rate 0.0106
epoch 26, loss 0.4148, train acc 0.8603, test acc 0.9441, time 30.8 sec, tolerance  1, learning rate 0.0100
epoch 27, loss 0.3851, train acc 0.8750, test acc 0.9486, time 30.9 sec, tolerance  0, learning rate 0.0094
the best accuarcy is:  0.9491
the best accuarcy is:  0.9491
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.4071, train acc 0.8683, test acc 0.9517, time 31.0 sec, tolerance 10, learning rate 0.0010
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.4833, train acc 0.8395, test acc 0.9531, time 30.9 sec, tolerance 10, learning rate 0.0010
epoch 3, loss 0.4252, train acc 0.8619, test acc 0.9529, time 30.9 sec, tolerance  9, learning rate 0.0009
epoch 4, loss 0.4195, train acc 0.8594, test acc 0.9526, time 30.9 sec, tolerance  8, learning rate 0.0008
epoch 5, loss 0.4120, train acc 0.8631, test acc 0.9527, time 30.8 sec, tolerance  7, learning rate 0.0007
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.4189, train acc 0.8620, test acc 0.9538, time 31.0 sec, tolerance 10, learning rate 0.0005
epoch 7, loss 0.4489, train acc 0.8525, test acc 0.9525, time 30.9 sec, tolerance  9, learning rate 0.0003
epoch 8, loss 0.4237, train acc 0.8657, test acc 0.9533, time 30.9 sec, tolerance  8, learning rate 0.0002
epoch 9, loss 0.4349, train acc 0.8537, test acc 0.9528, time 30.9 sec, tolerance  7, learning rate 0.0001
epoch 10, loss 0.4208, train acc 0.8549, test acc 0.9538, time 30.8 sec, tolerance  6, learning rate 0.0000
the best accuarcy is:  0.9538
打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 1.0055, train acc 0.6697, test acc 0.8535, time 31.7 sec, tolerance 10, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.8246, train acc 0.7441, test acc 0.8850, time 31.0 sec, tolerance 10, learning rate 0.0190
epoch 3, loss 0.7999, train acc 0.7502, test acc 0.8743, time 31.0 sec, tolerance  9, learning rate 0.0280
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.6992, train acc 0.7871, test acc 0.9170, time 31.0 sec, tolerance 10, learning rate 0.0370
epoch 5, loss 0.6994, train acc 0.7843, test acc 0.8973, time 31.0 sec, tolerance  9, learning rate 0.0460
epoch 6, loss 0.6100, train acc 0.8075, test acc 0.9044, time 30.9 sec, tolerance  8, learning rate 0.0550
epoch 7, loss 0.6680, train acc 0.7916, test acc 0.9102, time 30.9 sec, tolerance  7, learning rate 0.0640
epoch 8, loss 0.6216, train acc 0.8064, test acc 0.9083, time 30.9 sec, tolerance  6, learning rate 0.0730
epoch 9, loss 0.5855, train acc 0.8134, test acc 0.9156, time 30.9 sec, tolerance  5, learning rate 0.0820
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 10, loss 0.5725, train acc 0.8186, test acc 0.9215, time 31.0 sec, tolerance 10, learning rate 0.0910
the best accuarcy is:  0.9215
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.5100, train acc 0.8371, test acc 0.9404, time 31.0 sec, tolerance 10, learning rate 0.0200
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.5166, train acc 0.8329, test acc 0.9406, time 31.0 sec, tolerance 10, learning rate 0.0200
epoch 3, loss 0.4718, train acc 0.8516, test acc 0.9403, time 30.9 sec, tolerance  9, learning rate 0.0199
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.4803, train acc 0.8470, test acc 0.9471, time 31.0 sec, tolerance 10, learning rate 0.0198
epoch 5, loss 0.5066, train acc 0.8306, test acc 0.9365, time 30.9 sec, tolerance  9, learning rate 0.0197
epoch 6, loss 0.4660, train acc 0.8517, test acc 0.9427, time 30.9 sec, tolerance  8, learning rate 0.0195
epoch 7, loss 0.4628, train acc 0.8478, test acc 0.9400, time 30.9 sec, tolerance  7, learning rate 0.0193
epoch 8, loss 0.4918, train acc 0.8411, test acc 0.9468, time 30.9 sec, tolerance  6, learning rate 0.0190
epoch 9, loss 0.4456, train acc 0.8590, test acc 0.9437, time 30.9 sec, tolerance  5, learning rate 0.0188
epoch 10, loss 0.4599, train acc 0.8485, test acc 0.9465, time 31.0 sec, tolerance  4, learning rate 0.0184
epoch 11, loss 0.4524, train acc 0.8538, test acc 0.9418, time 30.9 sec, tolerance  3, learning rate 0.0181
epoch 12, loss 0.4736, train acc 0.8429, test acc 0.9391, time 30.9 sec, tolerance  2, learning rate 0.0177
epoch 13, loss 0.4482, train acc 0.8549, test acc 0.9460, time 30.9 sec, tolerance  1, learning rate 0.0173
epoch 14, loss 0.4683, train acc 0.8478, test acc 0.9462, time 30.9 sec, tolerance  0, learning rate 0.0168
the best accuarcy is:  0.9471
the best accuarcy is:  0.9471
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.4833, train acc 0.8448, test acc 0.9484, time 31.3 sec, tolerance 10, learning rate 0.0010
epoch 2, loss 0.4799, train acc 0.8427, test acc 0.9480, time 30.9 sec, tolerance  9, learning rate 0.0010
epoch 3, loss 0.4781, train acc 0.8470, test acc 0.9483, time 30.8 sec, tolerance  8, learning rate 0.0009
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.4595, train acc 0.8529, test acc 0.9486, time 31.0 sec, tolerance 10, learning rate 0.0008
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 5, loss 0.5315, train acc 0.8263, test acc 0.9487, time 31.0 sec, tolerance 10, learning rate 0.0007
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.4429, train acc 0.8600, test acc 0.9501, time 31.0 sec, tolerance 10, learning rate 0.0005
epoch 7, loss 0.4561, train acc 0.8475, test acc 0.9494, time 30.9 sec, tolerance  9, learning rate 0.0003
epoch 8, loss 0.4622, train acc 0.8528, test acc 0.9492, time 30.9 sec, tolerance  8, learning rate 0.0002
epoch 9, loss 0.4493, train acc 0.8542, test acc 0.9495, time 30.9 sec, tolerance  7, learning rate 0.0001
epoch 10, loss 0.5166, train acc 0.8323, test acc 0.9500, time 30.9 sec, tolerance  6, learning rate 0.0000
the best accuarcy is:  0.9501
打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.9762, train acc 0.6835, test acc 0.8491, time 31.7 sec, tolerance 20, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.7771, train acc 0.7604, test acc 0.8746, time 30.9 sec, tolerance 20, learning rate 0.0190
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 3, loss 0.7374, train acc 0.7699, test acc 0.9017, time 31.0 sec, tolerance 20, learning rate 0.0280
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.7113, train acc 0.7772, test acc 0.9050, time 30.9 sec, tolerance 20, learning rate 0.0370
epoch 5, loss 0.6869, train acc 0.7854, test acc 0.8984, time 30.9 sec, tolerance 19, learning rate 0.0460
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.6583, train acc 0.7991, test acc 0.9149, time 31.0 sec, tolerance 20, learning rate 0.0550
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 7, loss 0.5920, train acc 0.8114, test acc 0.9221, time 30.9 sec, tolerance 20, learning rate 0.0640
epoch 8, loss 0.6270, train acc 0.8004, test acc 0.9217, time 30.9 sec, tolerance 19, learning rate 0.0730
epoch 9, loss 0.6016, train acc 0.8104, test acc 0.9044, time 30.8 sec, tolerance 18, learning rate 0.0820
epoch 10, loss 0.6248, train acc 0.8045, test acc 0.9030, time 30.9 sec, tolerance 17, learning rate 0.0910
the best accuarcy is:  0.9221
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.5888, train acc 0.8100, test acc 0.9367, time 30.9 sec, tolerance 20, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.5234, train acc 0.8316, test acc 0.9369, time 31.0 sec, tolerance 20, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 3, loss 0.5096, train acc 0.8373, test acc 0.9405, time 30.9 sec, tolerance 20, learning rate 0.0100
epoch 4, loss 0.4991, train acc 0.8398, test acc 0.9402, time 30.9 sec, tolerance 19, learning rate 0.0099
epoch 5, loss 0.4896, train acc 0.8423, test acc 0.9394, time 30.8 sec, tolerance 18, learning rate 0.0098
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.4822, train acc 0.8436, test acc 0.9435, time 30.9 sec, tolerance 20, learning rate 0.0098
epoch 7, loss 0.5092, train acc 0.8348, test acc 0.9424, time 31.0 sec, tolerance 19, learning rate 0.0096
epoch 8, loss 0.5275, train acc 0.8298, test acc 0.9424, time 30.9 sec, tolerance 18, learning rate 0.0095
epoch 9, loss 0.4974, train acc 0.8394, test acc 0.9413, time 30.9 sec, tolerance 17, learning rate 0.0094
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 10, loss 0.4885, train acc 0.8424, test acc 0.9458, time 30.9 sec, tolerance 20, learning rate 0.0092
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 11, loss 0.4569, train acc 0.8529, test acc 0.9472, time 31.0 sec, tolerance 20, learning rate 0.0090
epoch 12, loss 0.4578, train acc 0.8477, test acc 0.9449, time 30.9 sec, tolerance 19, learning rate 0.0089
epoch 13, loss 0.4852, train acc 0.8383, test acc 0.9439, time 30.9 sec, tolerance 18, learning rate 0.0086
epoch 14, loss 0.5169, train acc 0.8271, test acc 0.9446, time 30.9 sec, tolerance 17, learning rate 0.0084
epoch 15, loss 0.4904, train acc 0.8403, test acc 0.9458, time 30.8 sec, tolerance 16, learning rate 0.0082
epoch 16, loss 0.4359, train acc 0.8578, test acc 0.9452, time 30.9 sec, tolerance 15, learning rate 0.0079
epoch 17, loss 0.4420, train acc 0.8565, test acc 0.9463, time 30.9 sec, tolerance 14, learning rate 0.0077
epoch 18, loss 0.4349, train acc 0.8607, test acc 0.9465, time 30.9 sec, tolerance 13, learning rate 0.0074
epoch 19, loss 0.4215, train acc 0.8646, test acc 0.9452, time 30.9 sec, tolerance 12, learning rate 0.0071
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 20, loss 0.4465, train acc 0.8569, test acc 0.9503, time 30.9 sec, tolerance 20, learning rate 0.0068
epoch 21, loss 0.4111, train acc 0.8627, test acc 0.9464, time 30.9 sec, tolerance 19, learning rate 0.0065
epoch 22, loss 0.4054, train acc 0.8644, test acc 0.9478, time 30.9 sec, tolerance 18, learning rate 0.0062
epoch 23, loss 0.3907, train acc 0.8783, test acc 0.9503, time 30.9 sec, tolerance 17, learning rate 0.0059
epoch 24, loss 0.4546, train acc 0.8496, test acc 0.9466, time 30.9 sec, tolerance 16, learning rate 0.0056
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 25, loss 0.4349, train acc 0.8580, test acc 0.9505, time 31.0 sec, tolerance 20, learning rate 0.0053
epoch 26, loss 0.4436, train acc 0.8643, test acc 0.9479, time 30.8 sec, tolerance 19, learning rate 0.0050
epoch 27, loss 0.4033, train acc 0.8699, test acc 0.9489, time 31.0 sec, tolerance 18, learning rate 0.0047
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 28, loss 0.4122, train acc 0.8668, test acc 0.9515, time 31.0 sec, tolerance 20, learning rate 0.0044
epoch 29, loss 0.4097, train acc 0.8652, test acc 0.9514, time 30.9 sec, tolerance 19, learning rate 0.0041
epoch 30, loss 0.4210, train acc 0.8589, test acc 0.9503, time 30.8 sec, tolerance 18, learning rate 0.0038
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 31, loss 0.4296, train acc 0.8560, test acc 0.9535, time 30.9 sec, tolerance 20, learning rate 0.0035
epoch 32, loss 0.4104, train acc 0.8590, test acc 0.9533, time 30.9 sec, tolerance 19, learning rate 0.0032
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 33, loss 0.3721, train acc 0.8765, test acc 0.9542, time 30.9 sec, tolerance 20, learning rate 0.0029
epoch 34, loss 0.4369, train acc 0.8484, test acc 0.9523, time 30.8 sec, tolerance 19, learning rate 0.0026
epoch 35, loss 0.3926, train acc 0.8721, test acc 0.9532, time 30.9 sec, tolerance 18, learning rate 0.0023
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 36, loss 0.4098, train acc 0.8653, test acc 0.9551, time 31.0 sec, tolerance 20, learning rate 0.0021
epoch 37, loss 0.3510, train acc 0.8881, test acc 0.9548, time 30.9 sec, tolerance 19, learning rate 0.0018
epoch 38, loss 0.3786, train acc 0.8817, test acc 0.9538, time 30.9 sec, tolerance 18, learning rate 0.0016
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 39, loss 0.3516, train acc 0.8864, test acc 0.9560, time 30.9 sec, tolerance 20, learning rate 0.0014
epoch 40, loss 0.3671, train acc 0.8744, test acc 0.9546, time 30.9 sec, tolerance 19, learning rate 0.0012
epoch 41, loss 0.3942, train acc 0.8675, test acc 0.9546, time 30.9 sec, tolerance 18, learning rate 0.0010
epoch 42, loss 0.3902, train acc 0.8725, test acc 0.9555, time 30.9 sec, tolerance 17, learning rate 0.0008
epoch 43, loss 0.3861, train acc 0.8741, test acc 0.9556, time 30.9 sec, tolerance 16, learning rate 0.0006
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 44, loss 0.3987, train acc 0.8686, test acc 0.9565, time 31.0 sec, tolerance 20, learning rate 0.0005
epoch 45, loss 0.3738, train acc 0.8777, test acc 0.9561, time 30.9 sec, tolerance 19, learning rate 0.0004
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 46, loss 0.3566, train acc 0.8830, test acc 0.9572, time 31.0 sec, tolerance 20, learning rate 0.0003
epoch 47, loss 0.3972, train acc 0.8644, test acc 0.9555, time 30.9 sec, tolerance 19, learning rate 0.0002
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 48, loss 0.3877, train acc 0.8717, test acc 0.9575, time 31.0 sec, tolerance 20, learning rate 0.0001
epoch 49, loss 0.3393, train acc 0.8890, test acc 0.9557, time 30.9 sec, tolerance 19, learning rate 0.0000
epoch 50, loss 0.3584, train acc 0.8827, test acc 0.9565, time 30.9 sec, tolerance 18, learning rate 0.0000
the best accuarcy is:  0.9575
training on  cuda
epoch 1, loss 0.4103, train acc 0.8622, test acc 0.9564, time 31.0 sec, tolerance 19, learning rate 0.0010
epoch 2, loss 0.3620, train acc 0.8797, test acc 0.9548, time 30.8 sec, tolerance 18, learning rate 0.0010
epoch 3, loss 0.3791, train acc 0.8718, test acc 0.9554, time 30.9 sec, tolerance 17, learning rate 0.0009
epoch 4, loss 0.3528, train acc 0.8842, test acc 0.9566, time 30.9 sec, tolerance 16, learning rate 0.0008
epoch 5, loss 0.3155, train acc 0.8942, test acc 0.9564, time 30.9 sec, tolerance 15, learning rate 0.0007
epoch 6, loss 0.3965, train acc 0.8621, test acc 0.9571, time 30.9 sec, tolerance 14, learning rate 0.0005
epoch 7, loss 0.4178, train acc 0.8631, test acc 0.9553, time 30.9 sec, tolerance 13, learning rate 0.0003
epoch 8, loss 0.3639, train acc 0.8810, test acc 0.9568, time 30.9 sec, tolerance 12, learning rate 0.0002
epoch 9, loss 0.3892, train acc 0.8713, test acc 0.9566, time 30.9 sec, tolerance 11, learning rate 0.0001
epoch 10, loss 0.3834, train acc 0.8764, test acc 0.9566, time 30.9 sec, tolerance 10, learning rate 0.0000
the best accuarcy is:  0.9575
打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 1.2824, train acc 0.5821, test acc 0.8024, time 31.8 sec, tolerance 20, learning rate 0.0010
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.8507, train acc 0.7344, test acc 0.8583, time 31.0 sec, tolerance 20, learning rate 0.0019
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 3, loss 0.8001, train acc 0.7480, test acc 0.8824, time 31.1 sec, tolerance 20, learning rate 0.0028
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.7516, train acc 0.7668, test acc 0.8936, time 31.0 sec, tolerance 20, learning rate 0.0037
epoch 5, loss 0.6932, train acc 0.7868, test acc 0.8869, time 30.9 sec, tolerance 19, learning rate 0.0046
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.6981, train acc 0.7815, test acc 0.8992, time 31.0 sec, tolerance 20, learning rate 0.0055
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 7, loss 0.6291, train acc 0.8030, test acc 0.9143, time 31.0 sec, tolerance 20, learning rate 0.0064
epoch 8, loss 0.6275, train acc 0.8045, test acc 0.9086, time 30.9 sec, tolerance 19, learning rate 0.0073
epoch 9, loss 0.6636, train acc 0.7905, test acc 0.9126, time 30.9 sec, tolerance 18, learning rate 0.0082
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 10, loss 0.6599, train acc 0.7936, test acc 0.9192, time 31.0 sec, tolerance 20, learning rate 0.0091
the best accuarcy is:  0.9192
training on  cuda
epoch 1, loss 0.6004, train acc 0.8121, test acc 0.9187, time 30.9 sec, tolerance 19, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.6576, train acc 0.7923, test acc 0.9243, time 31.0 sec, tolerance 20, learning rate 0.0100
epoch 3, loss 0.5756, train acc 0.8209, test acc 0.9200, time 30.9 sec, tolerance 19, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.6004, train acc 0.8101, test acc 0.9326, time 31.1 sec, tolerance 20, learning rate 0.0099
epoch 5, loss 0.5402, train acc 0.8302, test acc 0.9231, time 30.9 sec, tolerance 19, learning rate 0.0098
epoch 6, loss 0.5625, train acc 0.8266, test acc 0.9267, time 30.9 sec, tolerance 18, learning rate 0.0098
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 7, loss 0.5644, train acc 0.8159, test acc 0.9329, time 31.0 sec, tolerance 20, learning rate 0.0096
epoch 8, loss 0.5309, train acc 0.8363, test acc 0.9329, time 31.0 sec, tolerance 19, learning rate 0.0095
epoch 9, loss 0.5446, train acc 0.8250, test acc 0.9294, time 30.9 sec, tolerance 18, learning rate 0.0094
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 10, loss 0.5072, train acc 0.8379, test acc 0.9364, time 31.0 sec, tolerance 20, learning rate 0.0092
epoch 11, loss 0.5390, train acc 0.8242, test acc 0.9363, time 31.0 sec, tolerance 19, learning rate 0.0090
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 12, loss 0.5147, train acc 0.8354, test acc 0.9401, time 31.1 sec, tolerance 20, learning rate 0.0089
epoch 13, loss 0.5639, train acc 0.8165, test acc 0.9342, time 31.0 sec, tolerance 19, learning rate 0.0086
epoch 14, loss 0.4487, train acc 0.8579, test acc 0.9326, time 30.9 sec, tolerance 18, learning rate 0.0084
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 15, loss 0.5323, train acc 0.8281, test acc 0.9415, time 31.1 sec, tolerance 20, learning rate 0.0082
epoch 16, loss 0.4351, train acc 0.8606, test acc 0.9392, time 31.0 sec, tolerance 19, learning rate 0.0079
epoch 17, loss 0.4521, train acc 0.8547, test acc 0.9398, time 31.0 sec, tolerance 18, learning rate 0.0077
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 18, loss 0.5204, train acc 0.8315, test acc 0.9420, time 31.1 sec, tolerance 20, learning rate 0.0074
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 19, loss 0.4726, train acc 0.8439, test acc 0.9452, time 31.0 sec, tolerance 20, learning rate 0.0071
epoch 20, loss 0.3994, train acc 0.8743, test acc 0.9441, time 30.9 sec, tolerance 19, learning rate 0.0068
epoch 21, loss 0.4627, train acc 0.8515, test acc 0.9385, time 31.0 sec, tolerance 18, learning rate 0.0065
epoch 22, loss 0.5090, train acc 0.8432, test acc 0.9449, time 31.0 sec, tolerance 17, learning rate 0.0062
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 23, loss 0.4879, train acc 0.8388, test acc 0.9481, time 31.1 sec, tolerance 20, learning rate 0.0059
epoch 24, loss 0.4853, train acc 0.8443, test acc 0.9438, time 31.0 sec, tolerance 19, learning rate 0.0056
epoch 25, loss 0.4331, train acc 0.8619, test acc 0.9463, time 31.0 sec, tolerance 18, learning rate 0.0053
epoch 26, loss 0.4076, train acc 0.8715, test acc 0.9452, time 31.0 sec, tolerance 17, learning rate 0.0050
epoch 27, loss 0.3717, train acc 0.8844, test acc 0.9447, time 30.9 sec, tolerance 16, learning rate 0.0047
epoch 28, loss 0.4293, train acc 0.8585, test acc 0.9468, time 30.9 sec, tolerance 15, learning rate 0.0044
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 29, loss 0.4434, train acc 0.8497, test acc 0.9485, time 31.0 sec, tolerance 20, learning rate 0.0041
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 30, loss 0.4800, train acc 0.8378, test acc 0.9496, time 31.1 sec, tolerance 20, learning rate 0.0038
epoch 31, loss 0.4199, train acc 0.8703, test acc 0.9492, time 31.0 sec, tolerance 19, learning rate 0.0035
epoch 32, loss 0.4118, train acc 0.8659, test acc 0.9496, time 31.0 sec, tolerance 18, learning rate 0.0032
epoch 33, loss 0.4115, train acc 0.8709, test acc 0.9488, time 31.0 sec, tolerance 17, learning rate 0.0029
epoch 34, loss 0.4082, train acc 0.8650, test acc 0.9488, time 31.0 sec, tolerance 16, learning rate 0.0026
epoch 35, loss 0.4161, train acc 0.8622, test acc 0.9493, time 31.0 sec, tolerance 15, learning rate 0.0023
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 36, loss 0.4057, train acc 0.8630, test acc 0.9519, time 31.0 sec, tolerance 20, learning rate 0.0021
epoch 37, loss 0.3737, train acc 0.8769, test acc 0.9510, time 31.0 sec, tolerance 19, learning rate 0.0018
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 38, loss 0.3746, train acc 0.8807, test acc 0.9531, time 31.0 sec, tolerance 20, learning rate 0.0016
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 39, loss 0.3641, train acc 0.8836, test acc 0.9540, time 31.0 sec, tolerance 20, learning rate 0.0014
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 40, loss 0.3388, train acc 0.8892, test acc 0.9557, time 31.0 sec, tolerance 20, learning rate 0.0012
epoch 41, loss 0.3974, train acc 0.8755, test acc 0.9526, time 31.0 sec, tolerance 19, learning rate 0.0010
epoch 42, loss 0.3846, train acc 0.8751, test acc 0.9549, time 31.0 sec, tolerance 18, learning rate 0.0008
epoch 43, loss 0.4378, train acc 0.8581, test acc 0.9551, time 30.9 sec, tolerance 17, learning rate 0.0006
epoch 44, loss 0.3668, train acc 0.8805, test acc 0.9540, time 31.0 sec, tolerance 16, learning rate 0.0005
epoch 45, loss 0.3919, train acc 0.8718, test acc 0.9545, time 30.9 sec, tolerance 15, learning rate 0.0004
epoch 46, loss 0.3554, train acc 0.8854, test acc 0.9550, time 30.9 sec, tolerance 14, learning rate 0.0003
epoch 47, loss 0.3904, train acc 0.8736, test acc 0.9549, time 30.9 sec, tolerance 13, learning rate 0.0002
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 48, loss 0.3811, train acc 0.8773, test acc 0.9560, time 31.0 sec, tolerance 20, learning rate 0.0001
epoch 49, loss 0.3674, train acc 0.8823, test acc 0.9552, time 30.9 sec, tolerance 19, learning rate 0.0000
epoch 50, loss 0.3899, train acc 0.8774, test acc 0.9553, time 30.9 sec, tolerance 18, learning rate 0.0000
the best accuarcy is:  0.956
training on  cuda
epoch 1, loss 0.3919, train acc 0.8736, test acc 0.9552, time 30.9 sec, tolerance 19, learning rate 0.0001
epoch 2, loss 0.3537, train acc 0.8873, test acc 0.9550, time 30.9 sec, tolerance 18, learning rate 0.0001
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 3, loss 0.4118, train acc 0.8612, test acc 0.9563, time 31.0 sec, tolerance 20, learning rate 0.0001
epoch 4, loss 0.3195, train acc 0.8992, test acc 0.9559, time 30.9 sec, tolerance 19, learning rate 0.0001
epoch 5, loss 0.3706, train acc 0.8778, test acc 0.9546, time 30.9 sec, tolerance 18, learning rate 0.0001
epoch 6, loss 0.4014, train acc 0.8659, test acc 0.9547, time 30.9 sec, tolerance 17, learning rate 0.0001
epoch 7, loss 0.4178, train acc 0.8558, test acc 0.9550, time 31.0 sec, tolerance 16, learning rate 0.0000
epoch 8, loss 0.3536, train acc 0.8871, test acc 0.9551, time 31.0 sec, tolerance 15, learning rate 0.0000
epoch 9, loss 0.3380, train acc 0.8927, test acc 0.9544, time 30.9 sec, tolerance 14, learning rate 0.0000
epoch 10, loss 0.3757, train acc 0.8766, test acc 0.9550, time 31.0 sec, tolerance 13, learning rate 0.0000
the best accuarcy is:  0.9563
打印网络结构(主要是为了确认如何调整)
Sequential(
  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
  (resnet_block1): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block3): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (resnet_block4): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (global_avg_pool): GlobalAvgPool2d()
  (fc): Sequential(
    (0): FlattenLayer()
    (1): Linear(in_features=512, out_features=10, bias=True)
  )
)
训练...
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.9960, train acc 0.6737, test acc 0.8629, time 31.8 sec, tolerance 20, learning rate 0.0100
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 2, loss 0.7892, train acc 0.7524, test acc 0.8944, time 31.1 sec, tolerance 20, learning rate 0.0190
epoch 3, loss 0.7458, train acc 0.7637, test acc 0.8869, time 30.9 sec, tolerance 19, learning rate 0.0280
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.6977, train acc 0.7781, test acc 0.9134, time 30.9 sec, tolerance 20, learning rate 0.0370
epoch 5, loss 0.6814, train acc 0.7909, test acc 0.9045, time 30.9 sec, tolerance 19, learning rate 0.0460
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 6, loss 0.6118, train acc 0.8115, test acc 0.9136, time 31.0 sec, tolerance 20, learning rate 0.0550
epoch 7, loss 0.6659, train acc 0.7915, test acc 0.9101, time 30.9 sec, tolerance 19, learning rate 0.0640
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 8, loss 0.5616, train acc 0.8225, test acc 0.9155, time 31.0 sec, tolerance 20, learning rate 0.0730
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 9, loss 0.6387, train acc 0.7932, test acc 0.9185, time 31.1 sec, tolerance 20, learning rate 0.0820
epoch 10, loss 0.6102, train acc 0.8070, test acc 0.9131, time 30.9 sec, tolerance 19, learning rate 0.0910
the best accuarcy is:  0.9185
training on  cuda
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 1, loss 0.5983, train acc 0.8128, test acc 0.9192, time 31.0 sec, tolerance 20, learning rate 0.1000
epoch 2, loss 0.6014, train acc 0.8078, test acc 0.9109, time 30.9 sec, tolerance 19, learning rate 0.1000
epoch 3, loss 0.5457, train acc 0.8298, test acc 0.9143, time 30.9 sec, tolerance 18, learning rate 0.0999
epoch 4, loss 0.5411, train acc 0.8259, test acc 0.9190, time 31.0 sec, tolerance 17, learning rate 0.0998
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 5, loss 0.5753, train acc 0.8166, test acc 0.9193, time 31.0 sec, tolerance 20, learning rate 0.0996
epoch 6, loss 0.5599, train acc 0.8209, test acc 0.9164, time 30.9 sec, tolerance 19, learning rate 0.0994
epoch 7, loss 0.5218, train acc 0.8278, test acc 0.9034, time 30.9 sec, tolerance 18, learning rate 0.0991
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 8, loss 0.5451, train acc 0.8288, test acc 0.9245, time 31.0 sec, tolerance 20, learning rate 0.0988
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 9, loss 0.5406, train acc 0.8251, test acc 0.9277, time 31.0 sec, tolerance 20, learning rate 0.0984
epoch 10, loss 0.5052, train acc 0.8396, test acc 0.9157, time 30.8 sec, tolerance 19, learning rate 0.0980
epoch 11, loss 0.5942, train acc 0.8097, test acc 0.9269, time 30.9 sec, tolerance 18, learning rate 0.0976
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 12, loss 0.5536, train acc 0.8203, test acc 0.9343, time 31.0 sec, tolerance 20, learning rate 0.0970
epoch 13, loss 0.5504, train acc 0.8193, test acc 0.9305, time 30.8 sec, tolerance 19, learning rate 0.0965
epoch 14, loss 0.5155, train acc 0.8312, test acc 0.9306, time 31.0 sec, tolerance 18, learning rate 0.0959
epoch 15, loss 0.5328, train acc 0.8271, test acc 0.8940, time 30.8 sec, tolerance 17, learning rate 0.0952
epoch 16, loss 0.4994, train acc 0.8405, test acc 0.9239, time 30.8 sec, tolerance 16, learning rate 0.0946
epoch 17, loss 0.5860, train acc 0.8078, test acc 0.9320, time 30.9 sec, tolerance 15, learning rate 0.0938
epoch 18, loss 0.5234, train acc 0.8312, test acc 0.9239, time 30.9 sec, tolerance 14, learning rate 0.0930
epoch 19, loss 0.5029, train acc 0.8369, test acc 0.9328, time 30.9 sec, tolerance 13, learning rate 0.0922
epoch 20, loss 0.5103, train acc 0.8382, test acc 0.9337, time 30.9 sec, tolerance 12, learning rate 0.0914
epoch 21, loss 0.5463, train acc 0.8195, test acc 0.9255, time 30.9 sec, tolerance 11, learning rate 0.0905
epoch 22, loss 0.5389, train acc 0.8255, test acc 0.9308, time 30.9 sec, tolerance 10, learning rate 0.0895
epoch 23, loss 0.5597, train acc 0.8137, test acc 0.9080, time 31.0 sec, tolerance  9, learning rate 0.0885
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 24, loss 0.5085, train acc 0.8348, test acc 0.9350, time 31.1 sec, tolerance 20, learning rate 0.0875
epoch 25, loss 0.5334, train acc 0.8272, test acc 0.9269, time 31.0 sec, tolerance 19, learning rate 0.0864
epoch 26, loss 0.4823, train acc 0.8464, test acc 0.9247, time 31.0 sec, tolerance 18, learning rate 0.0854
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 27, loss 0.5087, train acc 0.8348, test acc 0.9380, time 31.1 sec, tolerance 20, learning rate 0.0842
epoch 28, loss 0.4663, train acc 0.8488, test acc 0.9348, time 31.0 sec, tolerance 19, learning rate 0.0831
epoch 29, loss 0.5008, train acc 0.8383, test acc 0.9339, time 31.0 sec, tolerance 18, learning rate 0.0819
epoch 30, loss 0.4783, train acc 0.8451, test acc 0.9203, time 31.0 sec, tolerance 17, learning rate 0.0806
epoch 31, loss 0.4935, train acc 0.8397, test acc 0.9271, time 31.1 sec, tolerance 16, learning rate 0.0794
epoch 32, loss 0.4977, train acc 0.8456, test acc 0.9318, time 31.0 sec, tolerance 15, learning rate 0.0781
epoch 33, loss 0.4525, train acc 0.8514, test acc 0.9133, time 31.0 sec, tolerance 14, learning rate 0.0768
epoch 34, loss 0.4874, train acc 0.8427, test acc 0.9102, time 31.0 sec, tolerance 13, learning rate 0.0755
epoch 35, loss 0.4891, train acc 0.8399, test acc 0.9375, time 31.0 sec, tolerance 12, learning rate 0.0741
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 36, loss 0.5488, train acc 0.8195, test acc 0.9396, time 31.0 sec, tolerance 20, learning rate 0.0727
epoch 37, loss 0.4770, train acc 0.8454, test acc 0.9331, time 31.0 sec, tolerance 19, learning rate 0.0713
epoch 38, loss 0.4397, train acc 0.8557, test acc 0.9349, time 31.0 sec, tolerance 18, learning rate 0.0699
epoch 39, loss 0.4863, train acc 0.8445, test acc 0.9209, time 30.9 sec, tolerance 17, learning rate 0.0684
epoch 40, loss 0.4753, train acc 0.8431, test acc 0.9319, time 30.9 sec, tolerance 16, learning rate 0.0669
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 41, loss 0.5234, train acc 0.8269, test acc 0.9415, time 30.8 sec, tolerance 20, learning rate 0.0655
epoch 42, loss 0.5029, train acc 0.8342, test acc 0.9278, time 30.9 sec, tolerance 19, learning rate 0.0640
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 43, loss 0.4906, train acc 0.8414, test acc 0.9430, time 31.0 sec, tolerance 20, learning rate 0.0624
epoch 44, loss 0.4425, train acc 0.8580, test acc 0.9372, time 30.9 sec, tolerance 19, learning rate 0.0609
epoch 45, loss 0.5258, train acc 0.8253, test acc 0.9329, time 31.1 sec, tolerance 18, learning rate 0.0594
epoch 46, loss 0.5020, train acc 0.8448, test acc 0.9381, time 31.0 sec, tolerance 17, learning rate 0.0578
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 47, loss 0.4445, train acc 0.8550, test acc 0.9450, time 31.1 sec, tolerance 20, learning rate 0.0563
epoch 48, loss 0.4470, train acc 0.8544, test acc 0.9395, time 31.0 sec, tolerance 19, learning rate 0.0547
epoch 49, loss 0.4886, train acc 0.8404, test acc 0.9433, time 31.0 sec, tolerance 18, learning rate 0.0531
epoch 50, loss 0.4447, train acc 0.8582, test acc 0.9171, time 31.0 sec, tolerance 17, learning rate 0.0516
epoch 51, loss 0.4325, train acc 0.8594, test acc 0.9446, time 31.1 sec, tolerance 16, learning rate 0.0500
epoch 52, loss 0.4847, train acc 0.8403, test acc 0.9386, time 31.1 sec, tolerance 15, learning rate 0.0484
epoch 53, loss 0.4087, train acc 0.8653, test acc 0.9420, time 31.0 sec, tolerance 14, learning rate 0.0469
epoch 54, loss 0.3988, train acc 0.8712, test acc 0.9435, time 31.0 sec, tolerance 13, learning rate 0.0453
epoch 55, loss 0.4460, train acc 0.8544, test acc 0.9401, time 31.0 sec, tolerance 12, learning rate 0.0437
epoch 56, loss 0.4432, train acc 0.8572, test acc 0.9363, time 30.9 sec, tolerance 11, learning rate 0.0422
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 57, loss 0.4364, train acc 0.8576, test acc 0.9456, time 31.1 sec, tolerance 20, learning rate 0.0406
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 58, loss 0.4310, train acc 0.8609, test acc 0.9461, time 31.1 sec, tolerance 20, learning rate 0.0391
epoch 59, loss 0.4125, train acc 0.8651, test acc 0.9437, time 31.0 sec, tolerance 19, learning rate 0.0376
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 60, loss 0.4176, train acc 0.8669, test acc 0.9478, time 31.1 sec, tolerance 20, learning rate 0.0361
epoch 61, loss 0.4105, train acc 0.8656, test acc 0.9468, time 31.0 sec, tolerance 19, learning rate 0.0346
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 62, loss 0.4376, train acc 0.8569, test acc 0.9481, time 31.1 sec, tolerance 20, learning rate 0.0331
epoch 63, loss 0.4112, train acc 0.8624, test acc 0.9395, time 31.1 sec, tolerance 19, learning rate 0.0316
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 64, loss 0.4111, train acc 0.8611, test acc 0.9491, time 31.1 sec, tolerance 20, learning rate 0.0301
epoch 65, loss 0.4182, train acc 0.8623, test acc 0.9472, time 30.9 sec, tolerance 19, learning rate 0.0287
epoch 66, loss 0.3964, train acc 0.8688, test acc 0.9485, time 31.0 sec, tolerance 18, learning rate 0.0273
epoch 67, loss 0.4045, train acc 0.8688, test acc 0.9480, time 31.0 sec, tolerance 17, learning rate 0.0259
epoch 68, loss 0.3933, train acc 0.8699, test acc 0.9485, time 31.0 sec, tolerance 16, learning rate 0.0246
epoch 69, loss 0.4125, train acc 0.8639, test acc 0.9477, time 31.0 sec, tolerance 15, learning rate 0.0232
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 70, loss 0.4015, train acc 0.8680, test acc 0.9509, time 31.1 sec, tolerance 20, learning rate 0.0219
epoch 71, loss 0.3984, train acc 0.8660, test acc 0.9478, time 31.0 sec, tolerance 19, learning rate 0.0206
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 72, loss 0.4075, train acc 0.8650, test acc 0.9511, time 31.1 sec, tolerance 20, learning rate 0.0194
epoch 73, loss 0.4042, train acc 0.8663, test acc 0.9493, time 31.0 sec, tolerance 19, learning rate 0.0181
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 74, loss 0.4352, train acc 0.8503, test acc 0.9519, time 31.1 sec, tolerance 20, learning rate 0.0169
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 75, loss 0.3746, train acc 0.8748, test acc 0.9520, time 31.1 sec, tolerance 20, learning rate 0.0158
epoch 76, loss 0.3853, train acc 0.8707, test acc 0.9520, time 30.9 sec, tolerance 19, learning rate 0.0147
epoch 77, loss 0.3900, train acc 0.8727, test acc 0.9513, time 30.9 sec, tolerance 18, learning rate 0.0136
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 78, loss 0.3681, train acc 0.8769, test acc 0.9542, time 31.1 sec, tolerance 20, learning rate 0.0125
epoch 79, loss 0.3844, train acc 0.8739, test acc 0.9523, time 31.0 sec, tolerance 19, learning rate 0.0115
epoch 80, loss 0.3843, train acc 0.8706, test acc 0.9537, time 31.0 sec, tolerance 18, learning rate 0.0105
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 81, loss 0.3446, train acc 0.8817, test acc 0.9559, time 31.1 sec, tolerance 20, learning rate 0.0096
epoch 82, loss 0.3746, train acc 0.8768, test acc 0.9554, time 31.0 sec, tolerance 19, learning rate 0.0087
epoch 83, loss 0.3309, train acc 0.8907, test acc 0.9557, time 30.9 sec, tolerance 18, learning rate 0.0078
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 84, loss 0.3689, train acc 0.8749, test acc 0.9584, time 31.1 sec, tolerance 20, learning rate 0.0070
epoch 85, loss 0.2985, train acc 0.9028, test acc 0.9571, time 31.0 sec, tolerance 19, learning rate 0.0062
epoch 86, loss 0.3389, train acc 0.8847, test acc 0.9568, time 31.0 sec, tolerance 18, learning rate 0.0055
epoch 87, loss 0.3156, train acc 0.8963, test acc 0.9569, time 31.0 sec, tolerance 17, learning rate 0.0048
epoch 88, loss 0.3456, train acc 0.8850, test acc 0.9582, time 30.8 sec, tolerance 16, learning rate 0.0041
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 89, loss 0.3430, train acc 0.8765, test acc 0.9587, time 30.9 sec, tolerance 20, learning rate 0.0035
epoch 90, loss 0.3386, train acc 0.8883, test acc 0.9566, time 30.9 sec, tolerance 19, learning rate 0.0030
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 91, loss 0.3111, train acc 0.8930, test acc 0.9592, time 31.1 sec, tolerance 20, learning rate 0.0025
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 92, loss 0.3086, train acc 0.8959, test acc 0.9594, time 31.1 sec, tolerance 20, learning rate 0.0020
epoch 93, loss 0.3149, train acc 0.8947, test acc 0.9581, time 31.1 sec, tolerance 19, learning rate 0.0016
epoch 94, loss 0.3538, train acc 0.8796, test acc 0.9580, time 31.0 sec, tolerance 18, learning rate 0.0012
epoch 95, loss 0.3159, train acc 0.8940, test acc 0.9587, time 31.0 sec, tolerance 17, learning rate 0.0009
epoch 96, loss 0.3461, train acc 0.8822, test acc 0.9587, time 31.0 sec, tolerance 16, learning rate 0.0006
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 97, loss 0.2912, train acc 0.9058, test acc 0.9600, time 31.1 sec, tolerance 20, learning rate 0.0004
epoch 98, loss 0.3606, train acc 0.8798, test acc 0.9582, time 31.0 sec, tolerance 19, learning rate 0.0002
epoch 99, loss 0.3173, train acc 0.8959, test acc 0.9593, time 31.1 sec, tolerance 18, learning rate 0.0001
epoch 100, loss 0.3403, train acc 0.8849, test acc 0.9594, time 31.0 sec, tolerance 17, learning rate 0.0000
the best accuarcy is:  0.96
training on  cuda
epoch 1, loss 0.3717, train acc 0.8699, test acc 0.9593, time 31.0 sec, tolerance 19, learning rate 0.0010
epoch 2, loss 0.3403, train acc 0.8816, test acc 0.9597, time 31.1 sec, tolerance 18, learning rate 0.0010
epoch 3, loss 0.3431, train acc 0.8803, test acc 0.9588, time 31.0 sec, tolerance 17, learning rate 0.0009
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 4, loss 0.3399, train acc 0.8824, test acc 0.9602, time 31.1 sec, tolerance 20, learning rate 0.0008
find best! save at /home/gongxj/students/houys/git_repo/pytorch_learning/notebooks/project/model/best.pth
epoch 5, loss 0.3336, train acc 0.8923, test acc 0.9604, time 31.1 sec, tolerance 20, learning rate 0.0007
epoch 6, loss 0.3485, train acc 0.8790, test acc 0.9592, time 31.0 sec, tolerance 19, learning rate 0.0005
epoch 7, loss 0.3401, train acc 0.8850, test acc 0.9596, time 31.1 sec, tolerance 18, learning rate 0.0003
epoch 8, loss 0.2800, train acc 0.9142, test acc 0.9599, time 31.0 sec, tolerance 17, learning rate 0.0002
epoch 9, loss 0.2641, train acc 0.9125, test acc 0.9602, time 30.9 sec, tolerance 16, learning rate 0.0001
epoch 10, loss 0.3387, train acc 0.8870, test acc 0.9597, time 31.0 sec, tolerance 15, learning rate 0.0000
the best accuarcy is:  0.9604
